{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "from gensim.models import fasttext\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io, os\n",
    "import nltk, time, re, string, pickle\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory, StopWordRemover, ArrayDictionary\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import lightgbm as lgb\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast \n",
    "def get_file():\n",
    "    with open('dataset/normalisasi.txt') as f:\n",
    "        data_normalisai = f.read()\n",
    "    normalization_words = ast.literal_eval(data_normalisai)\n",
    "\n",
    "    with open('dataset/stopwords.txt') as f:\n",
    "        data_stopwords = f.read()\n",
    "        stopwords = ast.literal_eval(data_stopwords)\n",
    "\n",
    "    return normalization_words, stopwords\n",
    "\n",
    "normalization_words, stopwords = get_file()\n",
    "\n",
    "def normalisasi(texts):\n",
    "    finalText = []\n",
    "    splitted_text = texts.split()\n",
    "    for text in splitted_text:\n",
    "        if text in normalization_words:\n",
    "            finalText.append(normalization_words[text])\n",
    "        else:\n",
    "            finalText.append(text)\n",
    "      \n",
    "    return \" \".join(finalText)\n",
    "\n",
    "def hapus_stopword(text):\n",
    "#     stopword_factory = stopwords\n",
    "\n",
    "    sw_dict = ArrayDictionary(stopwords)\n",
    "    temp = StopWordRemover(sw_dict)\n",
    "\n",
    "    text = temp.remove(text)\n",
    "    return text\n",
    "\n",
    "# def tokenize(text):\n",
    "#     text = nltk.tokenize.word_tokenize(text)\n",
    "#     return text\n",
    "\n",
    "def hapus_duplikasi_kata(text):\n",
    "    res = []\n",
    "    text = text.split()\n",
    "    for i in text:\n",
    "        if i in res:\n",
    "            text.remove(i)\n",
    "        else:\n",
    "            res.append(i)\n",
    "    return \" \".join(text)\n",
    "\n",
    "def stemming(text):\n",
    "    factory = StemmerFactory()\n",
    "    stemmer = factory.create_stemmer()\n",
    "    text = stemmer.stem(text)\n",
    "    return text\n",
    "\n",
    "def case_folding(text):\n",
    "    text = text.lower()\n",
    "    # remove space in front of and at the end text\n",
    "    text = text.strip()\n",
    "    # remove space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # remove number\n",
    "    text = re.sub(r\"\\d+\", \" \", text)\n",
    "    # remove punctuation\n",
    "    for i in text:\n",
    "        if i in list(string.punctuation):\n",
    "            text = text.replace(i, \" \")\n",
    "\n",
    "    return text\n",
    "\n",
    "def preprocessing_data(opinion):\n",
    "    opinion = case_folding(opinion)\n",
    "    opinion = normalisasi(opinion)\n",
    "    opinion = hapus_stopword(opinion)\n",
    "    opinion = hapus_duplikasi_kata(opinion)\n",
    "    opinion = stemming(opinion)\n",
    "    return opinion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tempat</th>\n",
       "      <th>Opinion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tempat</td>\n",
       "      <td>Positif</td>\n",
       "      <td>4</td>\n",
       "      <td>Karena tempatnya memadai dan antrian teratur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tempat</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>2</td>\n",
       "      <td>lumayan berdesakan dan tdk menerapkan social d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tempat</td>\n",
       "      <td>Positif</td>\n",
       "      <td>3</td>\n",
       "      <td>terkadang terlalu ramai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tempat</td>\n",
       "      <td>Positif</td>\n",
       "      <td>4</td>\n",
       "      <td>Tempat bersih dan luas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tempat</td>\n",
       "      <td>Positif</td>\n",
       "      <td>4</td>\n",
       "      <td>Tempat vaksinasi sangat layak karena pihak pen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Aspect Sentiment  Tempat                                            Opinion\n",
       "0  Tempat   Positif       4       Karena tempatnya memadai dan antrian teratur\n",
       "1  Tempat   Negatif       2  lumayan berdesakan dan tdk menerapkan social d...\n",
       "2  Tempat   Positif       3                            terkadang terlalu ramai\n",
       "3  Tempat   Positif       4                             Tempat bersih dan luas\n",
       "4  Tempat   Positif       4  Tempat vaksinasi sangat layak karena pihak pen..."
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=pd.read_excel(\"DataKuesioner_Done.xlsx\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Opinion</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vaksinasi saat ini sudah mudah ditemukan diman...</td>\n",
       "      <td>Informasi</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>banyak infonya</td>\n",
       "      <td>Informasi</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Karena dapat info vaksin hanya dari kenalan yg...</td>\n",
       "      <td>Informasi</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jd ak puas km ak akhirnya tny ke temenku dan d...</td>\n",
       "      <td>Informasi</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Puas krn informasi udh bnyk beredar d twitter ...</td>\n",
       "      <td>Informasi</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Opinion     Aspect Sentiment\n",
       "0  Vaksinasi saat ini sudah mudah ditemukan diman...  Informasi   Positif\n",
       "1                                     banyak infonya  Informasi   Positif\n",
       "2  Karena dapat info vaksin hanya dari kenalan yg...  Informasi   Negatif\n",
       "3  Jd ak puas km ak akhirnya tny ke temenku dan d...  Informasi   Positif\n",
       "4  Puas krn informasi udh bnyk beredar d twitter ...  Informasi   Positif"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=pd.read_excel(\"app/dataset/DatasetMedsosPlus.xlsx\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "opinion = [preprocessing_data(sentence) for sentence in train.Opinion]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for index, row in train.iterrows():\n",
    "    sentences.append(preprocessing_data(row['Opinion']))\n",
    "new_sentences = [line.rstrip().split() for line in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7649795, 13717000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ftmodel = FastText(vector_size=4, window=3, min_count=1,workers=4,sg=0,hs=0)  # instantiate\n",
    "ftmodel.build_vocab(new_sentences)\n",
    "ftmodel.train(new_sentences, total_examples=len(new_sentences), epochs=1000)  # train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ftmodel.wv.most_similar(\"sertif\")\n",
    "'covid' in ftmodel.wv.key_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'pedulilindungi' in ftmodel.wv.key_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.6861366 ,  5.658009  , -0.10122687, -0.2918915 ], dtype=float32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = ftmodel.wv['pedulilindungi']\n",
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftmodel.save(\"ft_model_K.fasttext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = FastText.load(\"ft_model_K.fasttext\").wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'pedulilindungi' in ft.key_to_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input to the classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_vectorize(sentence):\n",
    "    sentence = preprocessing_data(sentence)\n",
    "    vecs = [ftmodel.wv[word] for word in word_tokenize(sentence)]\n",
    "    norm_vecs=[vec/np.linalg.norm(vec) for vec in vecs if np.linalg.norm(vec) > 0]\n",
    "    sent_vec=np.mean(norm_vecs, axis=0)\n",
    "    return abs(sent_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00557178, 0.07414879, 0.28766286, 0.75466776],\n",
       "       [0.546922  , 0.09524092, 0.05875815, 0.3720318 ],\n",
       "       [0.13127181, 0.16768269, 0.28982255, 0.8181853 ],\n",
       "       ...,\n",
       "       [0.03228225, 0.7340293 , 0.25319597, 0.09849533],\n",
       "       [0.46890587, 0.7073706 , 0.07470596, 0.02498829],\n",
       "       [0.52211255, 0.6371721 , 0.04989436, 0.19858241]], dtype=float32)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training\n",
    "vecs_train = [norm_vectorize(sentence) for sentence in train.Opinion]\n",
    "vectors_train = np.array(vecs_train, dtype=object)\n",
    "\n",
    "#Testing\n",
    "vecs = [norm_vectorize(sentence) for sentence in test.Opinion]\n",
    "vectors = np.array(vecs)\n",
    "vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2678, 4), (558, 4), (2678,), (558,))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sentiment = vectors_train\n",
    "y_train_sentiment = train.Sentiment\n",
    "\n",
    "X_test_sentiment = vectors\n",
    "y_test_sentiment = test.Sentiment\n",
    "\n",
    "X_train_sentiment.shape, X_test_sentiment.shape, y_train_sentiment.shape, y_test_sentiment.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='dart', max_depth=4, n_estimators=200,\n",
       "               num_leaves=8)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LGBMmodel = lgb.LGBMClassifier(boosting_type='dart', max_depth=4,num_leaves=8,n_estimators=200)\n",
    "LGBMmodel.fit(X_train_sentiment, y_train_sentiment) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7544802867383512\n",
      "Precision: 0.37859712230215825\n",
      "Recall: 0.49763593380614657\n",
      "F-1Score: 0.43003064351378956\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 135, 2, 421)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=LGBMmodel.predict(X_test_sentiment)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test_sentiment, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test_sentiment, y_pred, average='micro'))\n",
    "print(\"Recall:\",metrics.recall_score(y_test_sentiment, y_pred, average='micro'))\n",
    "print(\"F-1Score:\",metrics.f1_score(y_test_sentiment, y_pred, average='micro'))\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test_sentiment, y_pred).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=40, min_samples_split=4)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import Random Forest Model\n",
    "RFModel=RandomForestClassifier(max_depth=40, min_samples_split=4)\n",
    "RFModel.fit(X_train_sentiment,y_train_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the response for test dataset\n",
    "y_pred=RFModel.predict(X_test_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7473118279569892\n",
      "Precision: 0.5835227272727272\n",
      "Recall: 0.5231678486997636\n",
      "F-1Score: 0.4985947806137081\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 123, 18, 405)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test_sentiment, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test_sentiment, y_pred, average='micro'))\n",
    "print(\"Recall:\",metrics.recall_score(y_test_sentiment, y_pred, average='micro'))\n",
    "print(\"F-1Score:\",metrics.f1_score(y_test_sentiment, y_pred, average='micro'))\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test_sentiment, y_pred).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(probability=True)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVMmodel = svm.SVC(probability=True)\n",
    "SVMmodel.fit(X_train_sentiment, y_train_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = SVMmodel.predict(X_test_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7580645161290323\n",
      "Precision: 0.3790322580645161\n",
      "Recall: 0.5\n",
      "F-1Score: 0.43119266055045874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 135, 0, 423)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test_sentiment, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test_sentiment, y_pred, average='micro'))\n",
    "print(\"Recall:\",metrics.recall_score(y_test_sentiment, y_pred, average='micro'))\n",
    "print(\"F-1Score:\",metrics.f1_score(y_test_sentiment, y_pred, average='micro'))\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test_sentiment, y_pred).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NBModel = MultinomialNB()\n",
    "NBModel.fit(X_train_sentiment, y_train_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_nb = NBModel.predict(X_test_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7580645161290323\n",
      "Precision: 0.3790322580645161\n",
      "Recall: 0.5\n",
      "F-1Score: 0.43119266055045874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 135, 0, 423)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test_sentiment, y_pred_nb))\n",
    "print(\"Precision:\",metrics.precision_score(y_test_sentiment, y_pred_nb, average='micro'))\n",
    "print(\"Recall:\",metrics.recall_score(y_test_sentiment, y_pred_nb, average='micro'))\n",
    "print(\"F-1Score:\",metrics.f1_score(y_test_sentiment, y_pred_nb, average='micro'))\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test_sentiment, y_pred).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2678, 4), (558, 4), (2678,), (558,))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_aspect = vectors_train\n",
    "y_train_aspect = train.Aspect\n",
    "\n",
    "X_test_aspect = vectors\n",
    "y_test_aspect = test.Aspect\n",
    "\n",
    "X_train_aspect.shape, X_test_aspect.shape, y_train_aspect.shape, y_test_aspect.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='dart', max_depth=4, n_estimators=200,\n",
       "               num_leaves=8)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LGBAspectMmodel = lgb.LGBMClassifier(boosting_type='dart', max_depth=4,num_leaves=8,n_estimators=200)\n",
    "LGBAspectMmodel.fit(X_train_aspect, y_train_aspect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_aspect_pred=LGBAspectMmodel.predict(X_test_aspect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5752688172043011\n",
      "Precision: 0.5787988716661033\n",
      "Recall: 0.5703269213091183\n",
      "F-1Score: 0.5699771922118981\n",
      "[[95  1 14  9  3]\n",
      " [ 2 43 16 11 35]\n",
      " [12  5 68  3 12]\n",
      " [ 2 14  9 44 35]\n",
      " [ 1 18 11 24 71]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test_aspect, y_aspect_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test_aspect, y_aspect_pred, average='micro'))\n",
    "print(\"Recall:\",metrics.recall_score(y_test_aspect, y_aspect_pred, average='micro'))\n",
    "print(\"F-1Score:\",metrics.f1_score(y_test_aspect, y_aspect_pred, average='micro'))\n",
    "\n",
    "\n",
    "print(confusion_matrix(y_test_aspect,y_aspect_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=40, min_samples_split=4)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFAspectModel=RandomForestClassifier(max_depth=40, min_samples_split=4)\n",
    "RFAspectModel.fit(X_train_aspect,y_train_aspect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_aspect_pred=RFAspectModel.predict(X_test_aspect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5734767025089605\n",
      "Precision: 0.5719923543187767\n",
      "Recall: 0.5721742654771306\n",
      "F-1Score: 0.571988420947909\n",
      "[[97  3 12  4  6]\n",
      " [ 4 51 10 16 26]\n",
      " [12  7 67  7  7]\n",
      " [ 4 19  5 49 27]\n",
      " [ 3 32  8 26 56]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test_aspect, y_aspect_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test_aspect, y_aspect_pred, average='micro'))\n",
    "print(\"Recall:\",metrics.recall_score(y_test_aspect, y_aspect_pred, average='micro'))\n",
    "print(\"F-1Score:\",metrics.f1_score(y_test_aspect, y_aspect_pred, average='micro'))\n",
    "\n",
    "print(confusion_matrix(y_test_aspect,y_aspect_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(probability=True)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVMAspectModel = svm.SVC(probability=True)\n",
    "SVMAspectModel.fit(X_train_aspect, y_train_aspect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_aspect_pred = SVMAspectModel.predict(X_test_aspect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.578853046594982\n",
      "Precision: 0.5880874997963605\n",
      "Recall: 0.5771117724010324\n",
      "F-1Score: 0.5794394941933981\n",
      "[[96  2 12  4  8]\n",
      " [ 3 52 11  8 33]\n",
      " [ 9  8 70  2 11]\n",
      " [ 2 18  7 45 32]\n",
      " [ 1 32 12 20 60]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test_aspect, y_aspect_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test_aspect, y_aspect_pred, average='micro'))\n",
    "print(\"Recall:\",metrics.recall_score(y_test_aspect, y_aspect_pred, average='micro'))\n",
    "print(\"F-1Score:\",metrics.f1_score(y_test_aspect, y_aspect_pred, average='micro'))\n",
    "\n",
    "print(confusion_matrix(y_test_aspect,y_aspect_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NBAspectModel = MultinomialNB()\n",
    "NBAspectModel.fit(X_train_aspect, y_train_aspect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_aspect_pred = NBAspectModel.predict(X_test_aspect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.514336917562724\n",
      "Precision: 0.4753905294830264\n",
      "Recall: 0.49913442622950815\n",
      "F-1Score: 0.46675593568507984\n",
      "[[100   0   3   9  10]\n",
      " [  6   0   6  12  83]\n",
      " [ 12   0  48   7  33]\n",
      " [  3   0   1  52  48]\n",
      " [ 12   0   3  23  87]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test_aspect, y_aspect_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test_aspect, y_aspect_pred, average='micro'))\n",
    "print(\"Recall:\",metrics.recall_score(y_test_aspect, y_aspect_pred, average='micro'))\n",
    "print(\"F-1Score:\",metrics.f1_score(y_test_aspect, y_aspect_pred, average='micro'))\n",
    "\n",
    "print(confusion_matrix(y_test_aspect,y_aspect_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just load the pretrained but can't extend train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "ftpremodel = fasttext.load_facebook_vectors(\"cc.id.300.bin.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cek kata OOV (Out of Vocab)\n",
    "'pedulilindungi' in ftpremodel.key_to_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extend Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_model = fasttext.load_facebook_model(\"cc.id.300.bin.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'covid' in fb_model.wv.key_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "new_df=test\n",
    "sentences = [preprocessing_data(r['Opinion']) for i,r in new_df.iterrows()]\n",
    "new_sentences= [line.rstrip().split() for line in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(657, 3110)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fb_model.build_vocab(new_sentences, update=True)\n",
    "fb_model.train(new_sentences, total_examples=len(new_sentences), epochs=fb_model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'pedulilindungi' in fb_model.wv.key_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.35805307e-03,  2.02784175e-03,  3.36957537e-02,  4.61445712e-02,\n",
       "       -6.47531776e-03, -2.52631977e-02, -9.50048736e-04,  3.95988766e-03,\n",
       "       -1.03563005e-02, -7.88780153e-02, -6.19595777e-03,  5.14757540e-03,\n",
       "       -1.20040271e-02, -2.71068346e-02,  9.76053067e-03,  1.34323891e-02,\n",
       "        1.16706146e-02, -3.95376701e-03,  2.39801016e-02,  9.34991986e-03,\n",
       "       -4.92930152e-02, -1.03336032e-02,  1.03500271e-02,  6.14447566e-03,\n",
       "       -7.61731202e-03, -8.82517826e-03,  4.00772411e-03, -7.30433362e-03,\n",
       "        1.53391045e-02, -6.56296127e-03,  1.64408851e-02, -3.30553181e-03,\n",
       "        2.27560308e-02, -4.63086274e-03,  1.77889094e-02,  8.45407369e-04,\n",
       "       -4.96898359e-03,  9.92843974e-03,  2.00049742e-03,  1.35488641e-02,\n",
       "        2.61881948e-02, -8.92075337e-03, -5.07425703e-03,  6.21333194e-04,\n",
       "        1.80275366e-02,  1.02109034e-02,  2.80487002e-03, -3.77324224e-03,\n",
       "        9.48821846e-03, -1.31758712e-02, -7.63672870e-03,  2.99243513e-03,\n",
       "       -6.04465837e-03, -3.53942811e-02,  1.39464671e-02,  2.16011330e-02,\n",
       "        2.52996217e-02, -7.85829686e-03, -1.43033871e-02, -4.91580041e-03,\n",
       "        7.22554838e-03,  8.84094462e-03,  6.84679765e-03, -1.18825501e-02,\n",
       "        2.26727705e-02,  1.17743444e-02, -5.02091926e-03,  8.18551891e-03,\n",
       "       -1.66992471e-02, -1.22411698e-02,  1.39839007e-02,  2.25190520e-02,\n",
       "        7.16192462e-03,  9.33451951e-03, -5.91219461e-04, -1.96010750e-02,\n",
       "        1.22053213e-02, -1.67555828e-02, -1.65340910e-03,  4.62054973e-03,\n",
       "        5.99481072e-03, -2.45135427e-02, -1.56842060e-02, -3.28001333e-03,\n",
       "       -1.87533889e-02,  1.03145046e-02, -1.62437242e-02, -4.06153351e-02,\n",
       "       -1.58647615e-02, -2.02125013e-02,  7.05562625e-03,  7.70459743e-03,\n",
       "       -3.04982550e-02,  2.01765019e-02, -2.07240100e-05, -4.65759687e-04,\n",
       "       -2.27967999e-03, -5.68733877e-03, -1.02949906e-02,  1.62209719e-02,\n",
       "       -1.64805204e-02,  6.02638163e-03,  8.82270094e-03,  6.85526663e-03,\n",
       "        4.70846072e-02,  7.10060413e-04, -4.39828355e-03, -1.45014068e-02,\n",
       "       -4.53998288e-03,  2.63619423e-03, -1.41869206e-02,  5.96961845e-03,\n",
       "        5.41726779e-03,  1.82943381e-02, -1.40603390e-02, -3.35310446e-03,\n",
       "        1.16330211e-03, -7.81866070e-03, -1.49948681e-02, -2.28682044e-03,\n",
       "       -1.20765371e-02,  2.02504685e-03,  2.14068703e-02,  1.49618147e-03,\n",
       "       -2.54023112e-02, -1.32447314e-02, -1.17941492e-03, -1.87600758e-02,\n",
       "       -2.26376429e-02, -1.68793611e-02,  5.96673833e-03,  9.35180485e-03,\n",
       "        5.10088447e-03,  1.69752259e-02,  1.24586932e-02, -1.90718174e-02,\n",
       "       -3.01089790e-03,  4.61562676e-03,  1.32719046e-02, -3.70495068e-03,\n",
       "        1.41663048e-02, -9.90244076e-02,  4.49279696e-03,  6.72140718e-03,\n",
       "       -7.41258776e-03,  1.59310382e-02, -7.93723948e-03, -4.90585156e-03,\n",
       "        1.96315092e-03, -1.75151660e-03,  2.80779619e-02,  1.52801536e-02,\n",
       "       -3.42306623e-04,  8.97824019e-03,  5.03387526e-02, -4.40904079e-03,\n",
       "        3.13999616e-02, -3.23014669e-02,  7.46330363e-04, -2.36477833e-02,\n",
       "       -2.28268877e-02,  5.53327166e-02, -3.94950546e-02, -9.84124281e-03,\n",
       "        1.02835044e-03,  1.99093614e-02, -6.42392132e-03,  6.16265507e-03,\n",
       "        3.68330255e-03, -1.71399191e-02, -1.67281460e-02,  9.63392900e-04,\n",
       "        3.22444588e-02,  7.57096149e-03,  6.83203014e-03, -1.54274087e-02,\n",
       "       -6.36607350e-04,  2.89311842e-03, -7.88535737e-03,  2.05752123e-02,\n",
       "        4.84613441e-02,  7.98575021e-03,  6.15616608e-03, -2.32607089e-02,\n",
       "        1.60072818e-02,  5.19026024e-03,  1.15115531e-02,  2.34165713e-02,\n",
       "        3.28297950e-02, -5.44011011e-04,  6.80540223e-03,  1.55458469e-02,\n",
       "        4.73055057e-03,  9.13828798e-03,  1.04751054e-03,  2.12652469e-03,\n",
       "        1.91515349e-02,  1.66159645e-02, -6.40004000e-04,  4.26944420e-02,\n",
       "        4.84595448e-03,  1.48739051e-02, -9.50454210e-04,  1.22302761e-02,\n",
       "       -8.42288602e-03, -1.41620226e-02, -1.07146269e-02,  9.27979778e-03,\n",
       "        2.04353733e-03,  1.61746666e-02,  1.74304284e-02, -1.77276805e-02,\n",
       "        8.21449430e-05, -1.97371072e-03,  5.41667081e-03, -1.17281522e-03,\n",
       "        6.38364302e-03,  1.96478865e-03, -1.16217174e-02, -5.58645800e-02,\n",
       "        1.16769588e-02, -5.46762394e-03, -1.00542549e-02, -3.13529489e-03,\n",
       "       -5.01471804e-03,  1.87053327e-02, -3.56418677e-02,  1.13515360e-02,\n",
       "       -3.62023129e-03, -1.10187326e-02, -6.55778311e-03, -8.91716965e-03,\n",
       "        1.02470582e-02,  3.03485878e-02,  9.32318810e-03, -7.99113326e-03,\n",
       "       -2.61849444e-02, -5.39151300e-03, -5.37990883e-04, -7.39411544e-03,\n",
       "        2.44560950e-02,  7.81968050e-03, -3.03095348e-05, -1.04362685e-02,\n",
       "       -2.36777756e-02,  6.85599574e-04, -7.37894140e-03,  5.82718197e-03,\n",
       "       -1.67803969e-02, -1.98447630e-02, -7.56646460e-03, -2.18838472e-02,\n",
       "        3.55940592e-03,  2.64395680e-02, -3.83459311e-03,  5.15404763e-03,\n",
       "       -1.02852583e-02,  9.12646577e-03,  1.18566761e-02,  3.01405205e-03,\n",
       "        9.80655756e-03, -7.33289821e-03, -2.13792957e-02,  2.07866472e-03,\n",
       "        7.33193010e-03, -9.37179197e-03,  9.70506668e-03,  1.67092506e-03,\n",
       "       -6.46952819e-03,  1.04065482e-02,  1.17011918e-02, -1.19397352e-02,\n",
       "       -1.80295669e-02,  9.96634271e-03, -7.70948362e-03,  1.20631838e-03,\n",
       "       -3.77854742e-02,  4.65823943e-03, -5.55155948e-02,  1.92360189e-02,\n",
       "       -2.44084932e-02, -1.31167297e-03, -2.90111406e-03, -1.22642927e-02,\n",
       "       -2.12191744e-03, -2.80298982e-02, -6.03552628e-03, -9.09334887e-03,\n",
       "        1.22572388e-02, -1.26904612e-02, -1.06707902e-03, -1.32499635e-03,\n",
       "       -1.87804084e-02,  8.97103362e-03,  1.82280061e-03,  1.75445490e-02,\n",
       "        2.23963987e-03, -5.77979013e-02,  1.12227648e-02,  3.99250761e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iv_term = fb_model.wv['pedulilindungi']\n",
    "iv_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_model.save(\"extended_pretrain_ft_model.fasttext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = FastText.load(\"extended_pretrain_ft_model.fasttext\").wv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input to classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def norm_vectorize_pretrained(sentence):\n",
    "#     sentence = preprocessing_data(sentence)\n",
    "#     vecs = [fb_model.wv[word] for word in sentence]\n",
    "#     norm_vecs=[vec/np.linalg.norm(vec) for vec in vecs if np.linalg.norm(vec) > 0]\n",
    "#     sent_vec=np.mean(norm_vecs, axis=0)\n",
    "#     return sent_vec\n",
    "\n",
    "def norm_vectorize_pretrained(sentence):\n",
    "    sentence = preprocessing_data(sentence)\n",
    "    vecs = [fb_model.wv[word] for word in sentence]\n",
    "    norm_vecs=[vec/np.linalg.norm(vec) for vec in vecs if np.linalg.norm(vec) > 0]\n",
    "    sent_vec=abs(np.mean(norm_vecs, axis=0))\n",
    "    return sent_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03218957, 0.05214153, 0.04191422, ..., 0.05862442, 0.00639089,\n",
       "        0.06410597],\n",
       "       [0.02933587, 0.05753453, 0.04074798, ..., 0.06371552, 0.00401158,\n",
       "        0.0466414 ],\n",
       "       [0.03429855, 0.05343883, 0.03938835, ..., 0.06169917, 0.00141222,\n",
       "        0.06059257],\n",
       "       ...,\n",
       "       [0.03610053, 0.05608287, 0.03832653, ..., 0.05851021, 0.00088633,\n",
       "        0.05546058],\n",
       "       [0.0281581 , 0.05824663, 0.03507378, ..., 0.06291854, 0.0031361 ,\n",
       "        0.05602774],\n",
       "       [0.03203309, 0.05211883, 0.0370527 , ..., 0.05664467, 0.00704691,\n",
       "        0.0699681 ]], dtype=float32)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training\n",
    "vecs_train = [norm_vectorize_pretrained(sentence) for sentence in train.Opinion]\n",
    "vectors_train = np.array(vecs_train)\n",
    "\n",
    "#Testing\n",
    "vecs = [norm_vectorize_pretrained(sentence) for sentence in test.Opinion]\n",
    "vectors = np.array(vecs)\n",
    "vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2678, 300), (558, 300), (2678,), (558,))"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sentiment_pretrained = vectors_train\n",
    "y_train_sentiment_pretrained = train.Sentiment\n",
    "\n",
    "X_test_sentiment_pretrained = vectors\n",
    "y_test_sentiment_pretrained = test.Sentiment\n",
    "\n",
    "# X_train_sentiment_pretrained, X_test_sentiment_pretrained, y_train_sentiment_pretrained, y_test_sentiment_pretrained = train_test_split(X,y,test_size=0.2,stratify=y,random_state=42)\n",
    "X_train_sentiment_pretrained.shape, X_test_sentiment_pretrained.shape, y_train_sentiment_pretrained.shape, y_test_sentiment_pretrained.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='dart', learning_rate=0.8, max_depth=10,\n",
       "               num_leaves=10)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LGBMmodel = lgb.LGBMClassifier(boosting_type='dart', learning_rate=0.8, max_depth=10,num_leaves=10)\n",
    "LGBMmodel.fit(X_train_sentiment_pretrained, y_train_sentiment_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=LGBMmodel.predict(X_test_sentiment_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7526881720430108\n",
      "Precision: 0.6258266620257571\n",
      "Recall: 0.5569739952718676\n",
      "F-1 Score: 0.5548387096774194\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(24, 111, 27, 396)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test_sentiment_pretrained, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test_sentiment_pretrained, y_pred, average='macro'))\n",
    "print(\"Recall:\",metrics.recall_score(y_test_sentiment_pretrained, y_pred, average='macro'))\n",
    "print(\"F-1 Score:\",metrics.f1_score(y_test_sentiment_pretrained, y_pred, average='macro'))\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test_sentiment_pretrained, y_pred).ravel()\n",
    "(tn, fp, fn, tp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=40, min_samples_split=4)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFModel=RandomForestClassifier(max_depth=40, min_samples_split=4)\n",
    "RFModel.fit(X_train_sentiment_pretrained,y_train_sentiment_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=RFModel.predict(X_test_sentiment_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7670250896057348\n",
      "Precision: 0.7305575158786168\n",
      "Recall: 0.5286052009456265\n",
      "F-1 Score: 0.49366205048023226\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9, 126, 4, 419)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test_sentiment_pretrained, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test_sentiment_pretrained, y_pred, average='macro'))\n",
    "print(\"Recall:\",metrics.recall_score(y_test_sentiment_pretrained, y_pred, average='macro'))\n",
    "print(\"F-1 Score:\",metrics.f1_score(y_test_sentiment_pretrained, y_pred, average='macro'))\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test_sentiment_pretrained, y_pred).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(probability=True)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVMmodel = svm.SVC(probability=True)\n",
    "SVMmodel.fit(X_train_sentiment_pretrained, y_train_sentiment_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = SVMmodel.predict(X_test_sentiment_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7580645161290323\n",
      "Precision: 0.3790322580645161\n",
      "Recall: 0.5\n",
      "F-1 Score: 0.43119266055045874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 135, 0, 423)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test_sentiment_pretrained, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test_sentiment_pretrained, y_pred, average='macro'))\n",
    "print(\"Recall:\",metrics.recall_score(y_test_sentiment_pretrained, y_pred, average='macro'))\n",
    "print(\"F-1 Score:\",metrics.f1_score(y_test_sentiment_pretrained, y_pred, average='macro'))\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test_sentiment_pretrained, y_pred).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NBModel = MultinomialNB()\n",
    "NBModel.fit(X_train_sentiment_pretrained, y_train_sentiment_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = NBModel.predict(X_test_sentiment_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7580645161290323\n",
      "Precision: 0.3790322580645161\n",
      "Recall: 0.5\n",
      "F-1 Score: 0.43119266055045874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 135, 0, 423)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test_sentiment_pretrained, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test_sentiment_pretrained, y_pred, average='macro'))\n",
    "print(\"Recall:\",metrics.recall_score(y_test_sentiment_pretrained, y_pred, average='macro'))\n",
    "print(\"F-1 Score:\",metrics.f1_score(y_test_sentiment_pretrained, y_pred, average='macro'))\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test_sentiment_pretrained, y_pred).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2678, 300), (558, 300), (2678,), (558,))"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_aspect_pretrained = vectors_train\n",
    "y_train_aspect_pretrained =  train.Aspect\n",
    "\n",
    "X_test_aspect_pretrained = vectors\n",
    "y_test_aspect_pretrained = test.Aspect\n",
    "\n",
    "# X_train_aspect_pretrained, X_test_aspect_pretrained, y_train_aspect_pretrained, y_test_aspect_pretrained = train_test_split(X,y,test_size=0.2,stratify=y,random_state=42)\n",
    "X_train_aspect_pretrained.shape, X_test_aspect_pretrained.shape, y_train_aspect_pretrained.shape, y_test_aspect_pretrained.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='dart', max_depth=4, n_estimators=200,\n",
       "               num_leaves=8)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LGBAspectMmodel = lgb.LGBMClassifier(boosting_type='dart', max_depth=4,num_leaves=8,n_estimators=200)\n",
    "LGBAspectMmodel.fit(X_train_aspect_pretrained, y_train_aspect_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_aspect_pred=LGBAspectMmodel.predict(X_test_aspect_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6200716845878136\n",
      "Precision: 0.6251301207934691\n",
      "Recall: 0.6205257899140848\n",
      "F-1Score: 0.619942974456033\n",
      "Precision per class: [0.8125     0.59813084 0.66956522 0.44545455 0.6       ]\n",
      "[[78 10 11 10 13]\n",
      " [ 4 64  4 27  8]\n",
      " [ 2  0 77  8 13]\n",
      " [ 6 22  9 49 18]\n",
      " [ 6 11 14 16 78]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test_aspect_pretrained, y_aspect_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test_aspect_pretrained, y_aspect_pred, average='macro'))\n",
    "print(\"Recall:\",metrics.recall_score(y_test_aspect_pretrained, y_aspect_pred, average='macro'))\n",
    "print(\"F-1Score:\",metrics.f1_score(y_test_aspect_pretrained, y_aspect_pred, average='macro'))\n",
    "print(\"Precision per class:\",metrics.precision_score(y_test_aspect_pretrained, y_aspect_pred, average=None))\n",
    "\n",
    "print(confusion_matrix(y_test_aspect_pretrained,y_aspect_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=40)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a Aspect Classifier\n",
    "RFAspectModel=RandomForestClassifier(max_depth=40)\n",
    "RFAspectModel.fit(X_train_aspect_pretrained,y_train_aspect_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_aspect_pred=RFAspectModel.predict(X_test_aspect_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6236559139784946\n",
      "Precision: 0.6278641297218372\n",
      "Recall: 0.6230353914508963\n",
      "F-1Score: 0.6231700491010874\n",
      "Precision per class: [0.80808081 0.53913043 0.66666667 0.46428571 0.66115702]\n",
      "[[80 13  8 11 10]\n",
      " [ 5 62  7 26  7]\n",
      " [ 5  3 74  6 12]\n",
      " [ 3 27 10 52 12]\n",
      " [ 6 10 12 17 80]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test_aspect_pretrained, y_aspect_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test_aspect_pretrained, y_aspect_pred, average='macro'))\n",
    "print(\"Recall:\",metrics.recall_score(y_test_aspect_pretrained, y_aspect_pred, average='macro'))\n",
    "print(\"F-1Score:\",metrics.f1_score(y_test_aspect_pretrained, y_aspect_pred, average='macro'))\n",
    "print(\"Precision per class:\",metrics.precision_score(y_test_aspect_pretrained, y_aspect_pred, average=None))\n",
    "\n",
    "print(confusion_matrix(y_test_aspect_pretrained,y_aspect_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(probability=True)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVMAspectModel = svm.SVC(probability=True)\n",
    "SVMAspectModel.fit(X_train_aspect_pretrained, y_train_aspect_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_aspect_pred = SVMAspectModel.predict(X_test_aspect_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5770609318996416\n",
      "Precision: 0.5821552608971158\n",
      "Recall: 0.5750881191736102\n",
      "F-1Score: 0.5754624762644891\n",
      "Precision per class: [0.75       0.56989247 0.54545455 0.40983607 0.63559322]\n",
      "[[78  6 12 17  9]\n",
      " [ 7 53 12 28  7]\n",
      " [ 3  6 66  9 16]\n",
      " [ 6 24 13 50 11]\n",
      " [10  4 18 18 75]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test_aspect_pretrained, y_aspect_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test_aspect_pretrained, y_aspect_pred, average='macro'))\n",
    "print(\"Recall:\",metrics.recall_score(y_test_aspect_pretrained, y_aspect_pred, average='macro'))\n",
    "print(\"F-1Score:\",metrics.f1_score(y_test_aspect_pretrained, y_aspect_pred, average='macro'))\n",
    "print(\"Precision per class:\",metrics.precision_score(y_test_aspect_pretrained, y_aspect_pred, average=None))\n",
    "\n",
    "print(confusion_matrix(y_test_aspect_pretrained,y_aspect_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NBAspectModel = MultinomialNB()\n",
    "NBAspectModel.fit(X_train_aspect_pretrained, y_train_aspect_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_aspect_pred = NBAspectModel.predict(X_test_aspect_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4014336917562724\n",
      "Precision: 0.432216888038013\n",
      "Recall: 0.3742715371651483\n",
      "F-1Score: 0.3090408022005871\n",
      "Precision per class: [0.48387097 0.42857143 0.53846154 0.36       0.35018051]\n",
      "[[90  0  1  5 26]\n",
      " [25  3  2 29 48]\n",
      " [30  1  7  9 53]\n",
      " [19  3  2 27 53]\n",
      " [22  0  1  5 97]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test_aspect_pretrained, y_aspect_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test_aspect_pretrained, y_aspect_pred, average='macro'))\n",
    "print(\"Recall:\",metrics.recall_score(y_test_aspect_pretrained, y_aspect_pred, average='macro'))\n",
    "print(\"F-1Score:\",metrics.f1_score(y_test_aspect_pretrained, y_aspect_pred, average='macro'))\n",
    "print(\"Precision per class:\",metrics.precision_score(y_test_aspect_pretrained, y_aspect_pred, average=None))\n",
    "\n",
    "print(confusion_matrix(y_test_aspect_pretrained,y_aspect_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
