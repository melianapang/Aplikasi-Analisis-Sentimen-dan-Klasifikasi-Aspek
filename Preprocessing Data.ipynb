{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io, os\n",
    "import nltk, time, re, string, pickle\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory, StopWordRemover, ArrayDictionary\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast \n",
    "def get_file():\n",
    "    with open('dataset/normalisasi.txt') as f:\n",
    "        data_normalisai = f.read()\n",
    "    normalization_words = ast.literal_eval(data_normalisai)\n",
    "\n",
    "    with open('dataset/stopwords.txt') as f:\n",
    "        data_stopwords = f.read()\n",
    "        stopwords = ast.literal_eval(data_stopwords)\n",
    "\n",
    "    return normalization_words, stopwords\n",
    "\n",
    "normalization_words, stopwords = get_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalisasi(texts):\n",
    "    finalText = []\n",
    "    splitted_text = texts.split()\n",
    "    for text in splitted_text:\n",
    "        if text in normalization_words:\n",
    "            finalText.append(normalization_words[text])\n",
    "        else:\n",
    "            finalText.append(text)\n",
    "      \n",
    "    return \" \".join(finalText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hapus_stopword(text):\n",
    "    stopword_factory = stopwords\n",
    "\n",
    "    sw_dict = ArrayDictionary(stopword_factory)\n",
    "\n",
    "    temp = StopWordRemover(sw_dict)\n",
    "\n",
    "    text = temp.remove(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hapus_duplikasi_kata(text):\n",
    "    res = []\n",
    "    text = text.split()\n",
    "    for i in text:\n",
    "        if i in res:\n",
    "            text.remove(i)\n",
    "        else:\n",
    "            res.append(i)\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(text):\n",
    "    factory = StemmerFactory()\n",
    "    stemmer = factory.create_stemmer()\n",
    "    text = stemmer.stem(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def case_folding(text):\n",
    "    text = text.lower()\n",
    "    # remove space in front of and at the end text\n",
    "    text = text.strip()\n",
    "    # remove space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # remove number\n",
    "    text = re.sub(r\"\\d+\", \" \", text)\n",
    "    # remove punctuation\n",
    "    for i in text:\n",
    "        if i in list(string.punctuation):\n",
    "            text = text.replace(i, \" \")\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data(opinion):\n",
    "    opinion = case_folding(opinion)\n",
    "    opinion = normalisasi(opinion)\n",
    "    opinion = hapus_stopword(opinion)\n",
    "    opinion = hapus_duplikasi_kata(opinion)\n",
    "    opinion = stemming(opinion)\n",
    "    return opinion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tempat</th>\n",
       "      <th>Opinion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tempat</td>\n",
       "      <td>Positif</td>\n",
       "      <td>4</td>\n",
       "      <td>Karena tempatnya memadai dan antrian teratur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tempat</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>2</td>\n",
       "      <td>lumayan berdesakan dan tdk menerapkan social d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tempat</td>\n",
       "      <td>Positif</td>\n",
       "      <td>3</td>\n",
       "      <td>terkadang terlalu ramai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tempat</td>\n",
       "      <td>Positif</td>\n",
       "      <td>4</td>\n",
       "      <td>Tempat bersih dan luas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tempat</td>\n",
       "      <td>Positif</td>\n",
       "      <td>4</td>\n",
       "      <td>Tempat vaksinasi sangat layak karena pihak pen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Aspect Sentiment  Tempat                                            Opinion\n",
       "0  Tempat   Positif       4       Karena tempatnya memadai dan antrian teratur\n",
       "1  Tempat   Negatif       2  lumayan berdesakan dan tdk menerapkan social d...\n",
       "2  Tempat   Positif       3                            terkadang terlalu ramai\n",
       "3  Tempat   Positif       4                             Tempat bersih dan luas\n",
       "4  Tempat   Positif       4  Tempat vaksinasi sangat layak karena pihak pen..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=pd.read_excel(\"DataKuesioner_Done.xlsx\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Opinion</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vaksinasi saat ini sudah mudah ditemukan diman...</td>\n",
       "      <td>Informasi</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>banyak infonya</td>\n",
       "      <td>Informasi</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Karena dapat info vaksin hanya dari kenalan yg...</td>\n",
       "      <td>Informasi</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jd ak puas km ak akhirnya tny ke temenku dan d...</td>\n",
       "      <td>Informasi</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Puas krn informasi udh bnyk beredar d twitter ...</td>\n",
       "      <td>Informasi</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Opinion     Aspect Sentiment\n",
       "0  Vaksinasi saat ini sudah mudah ditemukan diman...  Informasi   Positif\n",
       "1                                     banyak infonya  Informasi   Positif\n",
       "2  Karena dapat info vaksin hanya dari kenalan yg...  Informasi   Negatif\n",
       "3  Jd ak puas km ak akhirnya tny ke temenku dan d...  Informasi   Positif\n",
       "4  Puas krn informasi udh bnyk beredar d twitter ...  Informasi   Positif"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=pd.read_excel(\"app/dataset/DatasetMedsosPlus.xlsx\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to txt for vocabulary\n",
    "train_vocab = []\n",
    "for i,row in train.iterrows():\n",
    "    preprocessedVocab = preprocessing_data(row['Opinion'])\n",
    "    train_vocab.append(preprocessedVocab)\n",
    "file_vocab.write(str(train_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold \n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = pickle.load(open('app/model/model_gridsearch_2/lgbm_sentiment_K.sav','rb'))\n",
    "# model_aspect = pickle.load(open('app/model/model_gridsearch/lgbm_aspect_K.sav','rb'))\n",
    "\n",
    "model = pickle.load(open('app/model/model_gridsearch_2/rf_sentiment_K.sav','rb'))\n",
    "model_aspect = pickle.load(open('app/model/model_gridsearch_2/rf_aspect_K_2.sav','rb'))\n",
    "\n",
    "# model = pickle.load(open('app/model/model_gridsearch_2/svm_sentiment_K.sav','rb'))\n",
    "# model_aspect = pickle.load(open('app/model/model_gridsearch_2/svm_aspect_K.sav','rb'))\n",
    "\n",
    "# model = pickle.load(open('app/model/model_baru/nb_sentiment_K.sav','rb'))\n",
    "# model_aspect = pickle.load(open('app/model/model_baru/nb_aspect_K.sav','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(lowercase='false')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer(lowercase='false')\n",
    "count_vect.fit(train_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stem = stemming\n",
    "Case = case_folding\n",
    "N = Normalization / normalisasi\n",
    "Stop = Stopword Removal / hapus_stopword\n",
    "D = Duplicate Words Removal / hapus_duplikasi_kata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  All Prep / Stem + Case + N + Stop + D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL:\n",
      ":Sentiment:\n",
      "Accuracy:  0.8494623655913979\n",
      "Precision:  0.7930992235477894\n",
      "Recall:  0.8351457840819543\n",
      "f1_score:  0.8093301007208293\n",
      ":Aspect:\n",
      "Accuracy:  0.8261648745519713\n",
      "Precision:  0.8344511163860249\n",
      "Recall:  0.8253296295859801\n",
      "f1_score:  0.8272740879575263\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "109 26 58 365\n",
      "[[101   4   4   5   8]\n",
      " [  1  79   1  24   2]\n",
      " [  0   0  90   0  10]\n",
      " [  1  14   0  82   7]\n",
      " [  1   3   1  11 109]]\n"
     ]
    }
   ],
   "source": [
    "X_train_processed=[]\n",
    "X_test_processed=[]\n",
    "y_sentiment_train =[]\n",
    "y_aspect_train =[]\n",
    "y_sentiment_test=[]\n",
    "y_aspect_test=[]\n",
    "\n",
    "for index, row in train.iterrows():\n",
    "    processedText = preprocessing_data(str(row['Opinion']))\n",
    "    X_train_processed.append(processedText)\n",
    "    y_sentiment_train.append(row['Sentiment'])\n",
    "    y_aspect_train.append(row['Aspect'])\n",
    "\n",
    "for index, row in test.iterrows():\n",
    "    processedText = preprocessing_data(str(row['Opinion']))\n",
    "    X_test_processed.append(processedText)\n",
    "    y_sentiment_test.append(row['Sentiment'])\n",
    "    y_aspect_test.append(row['Aspect'])\n",
    "    \n",
    "    \n",
    "X_train_vect = count_vect.transform(X_train_processed)\n",
    "X_test_vect = count_vect.transform(X_test_processed)\n",
    "\n",
    "X_train_vect = X_train_vect.toarray().astype(float)\n",
    "X_train_vect = np.array(X_train_vect, dtype='float64')\n",
    "\n",
    "X_test_vect = X_test_vect.toarray().astype(float)\n",
    "X_test_vect = np.array(X_test_vect, dtype='float64')\n",
    "\n",
    "model.fit(X_train_vect,y_sentiment_train)\n",
    "pred_values = model.predict(X_test_vect)\n",
    "\n",
    "acc = metrics.accuracy_score(y_sentiment_test, pred_values)\n",
    "precision = metrics.precision_score(y_sentiment_test, pred_values, average='macro')\n",
    "recall = metrics.recall_score(y_sentiment_test,pred_values, average='macro')\n",
    "f1 = metrics.f1_score(y_sentiment_test,pred_values, average='macro')    \n",
    "    \n",
    "print(\"ALL:\")\n",
    "print(\":Sentiment:\")\n",
    "print(\"Accuracy: \", acc)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"f1_score: \", f1)\n",
    "\n",
    "model_aspect.fit(X_train_vect,y_aspect_train)\n",
    "pred_aspect_values = model_aspect.predict(X_test_vect)\n",
    "\n",
    "acc = metrics.accuracy_score(y_aspect_test, pred_aspect_values)\n",
    "precision = metrics.precision_score(y_aspect_test, pred_aspect_values, average='macro')\n",
    "recall = metrics.recall_score(y_aspect_test,pred_aspect_values, average='macro')\n",
    "f1 = metrics.f1_score(y_aspect_test,pred_aspect_values, average='macro')    \n",
    "    \n",
    "print(\":Aspect:\")\n",
    "print(\"Accuracy: \", acc)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"f1_score: \", f1)\n",
    "\n",
    "print('\\n')\n",
    "print('\\n')\n",
    "print('\\n')\n",
    "tn, fp, fn, tp = confusion_matrix(y_sentiment_test, pred_values).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "print(confusion_matrix(y_aspect_test,pred_aspect_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEM:\n",
      ":Sentiment:\n",
      "Accuracy:  0.8422939068100358\n",
      "Precision:  0.783799120442616\n",
      "Recall:  0.8152876280535855\n",
      "f1_score:  0.796812155519142\n",
      ":Aspect:\n",
      "Accuracy:  0.8315412186379928\n",
      "Precision:  0.8381051467349024\n",
      "Recall:  0.8312619485922381\n",
      "f1_score:  0.8324726388374108\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "103 32 56 367\n",
      "[[103   2   4   6   7]\n",
      " [  1  82   1  22   1]\n",
      " [  1   0  89   1   9]\n",
      " [  1  10   0  84   9]\n",
      " [  0   5   5   9 106]]\n"
     ]
    }
   ],
   "source": [
    "X_train_processed=[]\n",
    "X_test_processed=[]\n",
    "y_sentiment_train =[]\n",
    "y_aspect_train =[]\n",
    "y_sentiment_test=[]\n",
    "y_aspect_test=[]\n",
    "\n",
    "for index, row in train.iterrows():\n",
    "    processedText = stemming(str(row['Opinion']))\n",
    "    X_train_processed.append(processedText)\n",
    "    y_sentiment_train.append(row['Sentiment'])\n",
    "    y_aspect_train.append(row['Aspect'])\n",
    "\n",
    "for index, row in test.iterrows():\n",
    "    processedText = stemming(str(row['Opinion']))\n",
    "    X_test_processed.append(processedText)\n",
    "    y_sentiment_test.append(row['Sentiment'])\n",
    "    y_aspect_test.append(row['Aspect'])\n",
    "    \n",
    "    \n",
    "X_train_vect = count_vect.transform(X_train_processed)\n",
    "X_test_vect = count_vect.transform(X_test_processed)\n",
    "\n",
    "X_train_vect = X_train_vect.toarray().astype(float)\n",
    "X_train_vect = np.array(X_train_vect, dtype='float64')\n",
    "\n",
    "X_test_vect = X_test_vect.toarray().astype(float)\n",
    "X_test_vect = np.array(X_test_vect, dtype='float64')\n",
    "\n",
    "\n",
    "model.fit(X_train_vect,y_sentiment_train)\n",
    "pred_values = model.predict(X_test_vect)\n",
    "\n",
    "acc = metrics.accuracy_score(y_sentiment_test, pred_values)\n",
    "precision = metrics.precision_score(y_sentiment_test, pred_values, average='macro')\n",
    "recall = metrics.recall_score(y_sentiment_test,pred_values, average='macro')\n",
    "f1 = metrics.f1_score(y_sentiment_test,pred_values, average='macro')  \n",
    "\n",
    "print(\"STEM:\")\n",
    "print(\":Sentiment:\")\n",
    "print(\"Accuracy: \", acc)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"f1_score: \", f1)\n",
    "\n",
    "model_aspect.fit(X_train_vect,y_aspect_train)\n",
    "pred_aspect_values = model_aspect.predict(X_test_vect)\n",
    "\n",
    "acc = metrics.accuracy_score(y_aspect_test, pred_aspect_values)\n",
    "precision = metrics.precision_score(y_aspect_test, pred_aspect_values, average='macro')\n",
    "recall = metrics.recall_score(y_aspect_test,pred_aspect_values, average='macro')\n",
    "f1 = metrics.f1_score(y_aspect_test,pred_aspect_values, average='macro')    \n",
    "\n",
    "print(\":Aspect:\")\n",
    "print(\"Accuracy: \", acc)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"f1_score: \", f1)\n",
    "\n",
    "print('\\n')\n",
    "print('\\n')\n",
    "print('\\n')\n",
    "tn, fp, fn, tp = confusion_matrix(y_sentiment_test, pred_values).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "print(confusion_matrix(y_aspect_test,pred_aspect_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Folding + N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CF+N:\n",
      ":Sentiment:\n",
      "Accuracy:  0.8207885304659498\n",
      "Precision:  0.7574123989218329\n",
      "Recall:  0.785973207249803\n",
      "f1_score:  0.7691047221808431\n",
      ":Aspect:\n",
      "Accuracy:  0.8118279569892473\n",
      "Precision:  0.817004011102382\n",
      "Recall:  0.8110193609975133\n",
      "f1_score:  0.8117342984450675\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "97 38 62 361\n",
      "[[ 98   6   6   4   8]\n",
      " [  2  78   0  21   6]\n",
      " [  0   0  88   0  12]\n",
      " [  2  12   3  81   6]\n",
      " [  0   6   4   7 108]]\n"
     ]
    }
   ],
   "source": [
    "X_train_processed=[]\n",
    "X_test_processed=[]\n",
    "y_sentiment_train =[]\n",
    "y_aspect_train =[]\n",
    "y_sentiment_test=[]\n",
    "y_aspect_test=[]\n",
    "\n",
    "for index, row in train.iterrows():\n",
    "    processedText = case_folding(str(row['Opinion']))\n",
    "    processedText = normalisasi(processedText)\n",
    "    X_train_processed.append(processedText)\n",
    "    y_sentiment_train.append(row['Sentiment'])\n",
    "    y_aspect_train.append(row['Aspect'])\n",
    "\n",
    "for index, row in test.iterrows():\n",
    "    processedText = case_folding(str(row['Opinion']))\n",
    "    processedText = normalisasi(processedText)\n",
    "    X_test_processed.append(processedText)\n",
    "    y_sentiment_test.append(row['Sentiment'])\n",
    "    y_aspect_test.append(row['Aspect'])\n",
    "    \n",
    "    \n",
    "X_train_vect = count_vect.transform(X_train_processed)\n",
    "X_test_vect = count_vect.transform(X_test_processed)\n",
    "\n",
    "\n",
    "X_train_vect = X_train_vect.toarray().astype(float)\n",
    "X_train_vect = np.array(X_train_vect, dtype='float64')\n",
    "\n",
    "X_test_vect = X_test_vect.toarray().astype(float)\n",
    "X_test_vect = np.array(X_test_vect, dtype='float64')\n",
    "\n",
    "\n",
    "model.fit(X_train_vect,y_sentiment_train)\n",
    "pred_values = model.predict(X_test_vect)\n",
    "\n",
    "acc = metrics.accuracy_score(y_sentiment_test, pred_values)\n",
    "precision = metrics.precision_score(y_sentiment_test, pred_values, average='macro')\n",
    "recall = metrics.recall_score(y_sentiment_test,pred_values, average='macro')\n",
    "f1 = metrics.f1_score(y_sentiment_test,pred_values, average='macro')         \n",
    "    \n",
    "print(\"CF+N:\")\n",
    "print(\":Sentiment:\")\n",
    "print(\"Accuracy: \", acc)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"f1_score: \", f1)\n",
    "\n",
    "model_aspect.fit(X_train_vect,y_aspect_train)\n",
    "pred_aspect_values = model_aspect.predict(X_test_vect)\n",
    "\n",
    "acc = metrics.accuracy_score(y_aspect_test, pred_aspect_values)\n",
    "precision = metrics.precision_score(y_aspect_test, pred_aspect_values, average='macro')\n",
    "recall = metrics.recall_score(y_aspect_test,pred_aspect_values, average='macro')\n",
    "f1 = metrics.f1_score(y_aspect_test,pred_aspect_values, average='macro')       \n",
    "    \n",
    "print(\":Aspect:\")\n",
    "print(\"Accuracy: \", acc)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"f1_score: \", f1)\n",
    "\n",
    "print('\\n')\n",
    "print('\\n')\n",
    "print('\\n')\n",
    "tn, fp, fn, tp = confusion_matrix(y_sentiment_test, pred_values).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "print(confusion_matrix(y_aspect_test,pred_aspect_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Stop + D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SW+D:\n",
      ":Sentiment:\n",
      "Accuracy:  0.8082437275985663\n",
      "Precision:  0.7402941176470588\n",
      "Recall:  0.7575256107171\n",
      "f1_score:  0.7479004370131104\n",
      ":Aspect:\n",
      "Accuracy:  0.7885304659498208\n",
      "Precision:  0.7918037233037233\n",
      "Recall:  0.7858826649067188\n",
      "f1_score:  0.7875002029255362\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "89 46 61 362\n",
      "[[100   5   8   2   7]\n",
      " [  2  78   2  18   7]\n",
      " [  3   0  81   0  16]\n",
      " [  3  12   4  76   9]\n",
      " [  3   5   4   8 105]]\n"
     ]
    }
   ],
   "source": [
    "X_train_processed=[]\n",
    "X_test_processed=[]\n",
    "y_sentiment_train =[]\n",
    "y_aspect_train =[]\n",
    "y_sentiment_test=[]\n",
    "y_aspect_test=[]\n",
    "\n",
    "for index, row in train.iterrows():\n",
    "    processedText = hapus_stopword(str(row['Opinion']))\n",
    "    processedText = hapus_duplikasi_kata(processedText)\n",
    "    X_train_processed.append(processedText)\n",
    "    y_sentiment_train.append(row['Sentiment'])\n",
    "    y_aspect_train.append(row['Aspect'])\n",
    "\n",
    "for index, row in test.iterrows():\n",
    "    processedText = hapus_stopword(str(row['Opinion']))\n",
    "    processedText = hapus_duplikasi_kata(processedText)\n",
    "    X_test_processed.append(processedText)\n",
    "    y_sentiment_test.append(row['Sentiment'])\n",
    "    y_aspect_test.append(row['Aspect'])\n",
    "    \n",
    "    \n",
    "X_train_vect = count_vect.transform(X_train_processed)\n",
    "X_test_vect = count_vect.transform(X_test_processed)\n",
    "\n",
    "\n",
    "X_train_vect = X_train_vect.toarray().astype(float)\n",
    "X_train_vect = np.array(X_train_vect, dtype='float64')\n",
    "\n",
    "X_test_vect = X_test_vect.toarray().astype(float)\n",
    "X_test_vect = np.array(X_test_vect, dtype='float64')\n",
    "\n",
    "\n",
    "model.fit(X_train_vect,y_sentiment_train)\n",
    "pred_values = model.predict(X_test_vect)\n",
    "\n",
    "acc = metrics.accuracy_score(y_sentiment_test, pred_values)\n",
    "precision = metrics.precision_score(y_sentiment_test, pred_values, average='macro')\n",
    "recall = metrics.recall_score(y_sentiment_test,pred_values, average='macro')\n",
    "f1 = metrics.f1_score(y_sentiment_test,pred_values, average='macro')    \n",
    "    \n",
    "print(\"SW+D:\")\n",
    "print(\":Sentiment:\")\n",
    "print(\"Accuracy: \", acc)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"f1_score: \", f1)\n",
    "\n",
    "model_aspect.fit(X_train_vect,y_aspect_train)\n",
    "pred_aspect_values = model_aspect.predict(X_test_vect)\n",
    "\n",
    "acc = metrics.accuracy_score(y_aspect_test, pred_aspect_values)\n",
    "precision = metrics.precision_score(y_aspect_test, pred_aspect_values, average='macro')\n",
    "recall = metrics.recall_score(y_aspect_test,pred_aspect_values, average='macro')\n",
    "f1 = metrics.f1_score(y_aspect_test,pred_aspect_values, average='macro')    \n",
    "    \n",
    "print(\":Aspect:\")\n",
    "print(\"Accuracy: \", acc)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"f1_score: \", f1)\n",
    "\n",
    "print('\\n')\n",
    "print('\\n')\n",
    "print('\\n')\n",
    "tn, fp, fn, tp = confusion_matrix(y_sentiment_test, pred_values).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "print(confusion_matrix(y_aspect_test,pred_aspect_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stem + Case + N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S+CF+N:\n",
      ":Sentiment:\n",
      "Accuracy:  0.8530465949820788\n",
      "Precision:  0.7971111283684087\n",
      "Recall:  0.8349881796690308\n",
      "f1_score:  0.8122938579937973\n",
      ":Aspect:\n",
      "Accuracy:  0.8297491039426523\n",
      "Precision:  0.8286510560146925\n",
      "Recall:  0.828492953530306\n",
      "f1_score:  0.8278667631062687\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "108 27 55 368\n",
      "[[104   4   4   7   3]\n",
      " [  1  91   1  14   0]\n",
      " [  7   0  88   1   4]\n",
      " [  2  16   4  74   8]\n",
      " [  3   9   3   4 106]]\n"
     ]
    }
   ],
   "source": [
    "X_train_processed=[]\n",
    "X_test_processed=[]\n",
    "y_sentiment_train =[]\n",
    "y_aspect_train =[]\n",
    "y_sentiment_test=[]\n",
    "y_aspect_test=[]\n",
    "\n",
    "for index, row in train.iterrows():\n",
    "    processedText = stemming(str(row['Opinion']))\n",
    "    processedText = case_folding(processedText)\n",
    "    processedText = normalisasi(processedText)\n",
    "    X_train_processed.append(processedText)\n",
    "    y_sentiment_train.append(row['Sentiment'])\n",
    "    y_aspect_train.append(row['Aspect'])\n",
    "\n",
    "for index, row in test.iterrows():\n",
    "    processedText = stemming(str(row['Opinion']))\n",
    "    processedText = case_folding(processedText)\n",
    "    processedText = normalisasi(processedText)\n",
    "    X_test_processed.append(processedText)\n",
    "    y_sentiment_test.append(row['Sentiment'])\n",
    "    y_aspect_test.append(row['Aspect'])\n",
    "    \n",
    "    \n",
    "X_train_vect = count_vect.transform(X_train_processed)\n",
    "X_test_vect = count_vect.transform(X_test_processed)\n",
    "\n",
    "X_train_vect = X_train_vect.toarray().astype(float)\n",
    "X_train_vect = np.array(X_train_vect, dtype='float64')\n",
    "\n",
    "X_test_vect = X_test_vect.toarray().astype(float)\n",
    "X_test_vect = np.array(X_test_vect, dtype='float64')\n",
    "\n",
    "model.fit(X_train_vect,y_sentiment_train)\n",
    "pred_values = model.predict(X_test_vect)\n",
    "\n",
    "acc = metrics.accuracy_score(y_sentiment_test, pred_values)\n",
    "precision = metrics.precision_score(y_sentiment_test, pred_values, average='macro')\n",
    "recall = metrics.recall_score(y_sentiment_test,pred_values, average='macro')\n",
    "f1 = metrics.f1_score(y_sentiment_test,pred_values, average='macro')     \n",
    "    \n",
    "print(\"S+CF+N:\")\n",
    "print(\":Sentiment:\")\n",
    "print(\"Accuracy: \", acc)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"f1_score: \", f1)\n",
    "\n",
    "model_aspect.fit(X_train_vect,y_aspect_train)\n",
    "pred_aspect_values = model_aspect.predict(X_test_vect)\n",
    "\n",
    "acc = metrics.accuracy_score(y_aspect_test, pred_aspect_values)\n",
    "precision = metrics.precision_score(y_aspect_test, pred_aspect_values, average='macro')\n",
    "recall = metrics.recall_score(y_aspect_test,pred_aspect_values, average='macro')\n",
    "f1 = metrics.f1_score(y_aspect_test,pred_aspect_values, average='macro')    \n",
    "    \n",
    "print(\":Aspect:\")\n",
    "print(\"Accuracy: \", acc)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"f1_score: \", f1)\n",
    "\n",
    "print('\\n')\n",
    "print('\\n')\n",
    "print('\\n')\n",
    "tn, fp, fn, tp = confusion_matrix(y_sentiment_test, pred_values).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "print(confusion_matrix(y_aspect_test,pred_aspect_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stem + Stop + D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEM+SW+D:\n",
      ":Sentiment:\n",
      "Accuracy:  0.8440860215053764\n",
      "Precision:  0.7859493670886076\n",
      "Recall:  0.8164696611505122\n",
      "f1_score:  0.7986804291300869\n",
      ":Aspect:\n",
      "Accuracy:  0.8082437275985663\n",
      "Precision:  0.8177699152875559\n",
      "Recall:  0.8061738742030148\n",
      "f1_score:  0.8093068939721049\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "103 32 55 368\n",
      "[[ 99   3   5   5  10]\n",
      " [  2  81   1  20   3]\n",
      " [  1   0  85   1  13]\n",
      " [  3  13   0  77  11]\n",
      " [  0   3   2  11 109]]\n"
     ]
    }
   ],
   "source": [
    "X_train_processed=[]\n",
    "X_test_processed=[]\n",
    "y_sentiment_train =[]\n",
    "y_aspect_train =[]\n",
    "y_sentiment_test=[]\n",
    "y_aspect_test=[]\n",
    "\n",
    "for index, row in train.iterrows():\n",
    "    processedText = stemming(str(row['Opinion']))\n",
    "    processedText = hapus_stopword(processedText)\n",
    "    processedText = hapus_duplikasi_kata(processedText)\n",
    "    X_train_processed.append(processedText)\n",
    "    y_sentiment_train.append(row['Sentiment'])\n",
    "    y_aspect_train.append(row['Aspect'])\n",
    "\n",
    "for index, row in test.iterrows():\n",
    "    processedText = stemming(str(row['Opinion']))\n",
    "    processedText = hapus_stopword(processedText)\n",
    "    processedText = hapus_duplikasi_kata(processedText)\n",
    "    X_test_processed.append(processedText)\n",
    "    y_sentiment_test.append(row['Sentiment'])\n",
    "    y_aspect_test.append(row['Aspect'])\n",
    "    \n",
    "    \n",
    "X_train_vect = count_vect.transform(X_train_processed)\n",
    "X_test_vect = count_vect.transform(X_test_processed)\n",
    "\n",
    "X_train_vect = X_train_vect.toarray().astype(float)\n",
    "X_train_vect = np.array(X_train_vect, dtype='float64')\n",
    "\n",
    "X_test_vect = X_test_vect.toarray().astype(float)\n",
    "X_test_vect = np.array(X_test_vect, dtype='float64')\n",
    "\n",
    "model.fit(X_train_vect,y_sentiment_train)\n",
    "pred_values = model.predict(X_test_vect)\n",
    "\n",
    "acc = metrics.accuracy_score(y_sentiment_test, pred_values)\n",
    "precision = metrics.precision_score(y_sentiment_test, pred_values, average='macro')\n",
    "recall = metrics.recall_score(y_sentiment_test,pred_values, average='macro')\n",
    "f1 = metrics.f1_score(y_sentiment_test,pred_values, average='macro')        \n",
    "    \n",
    "print(\"STEM+SW+D:\")\n",
    "print(\":Sentiment:\")\n",
    "print(\"Accuracy: \", acc)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"f1_score: \", f1)\n",
    "\n",
    "model_aspect.fit(X_train_vect,y_aspect_train)\n",
    "pred_aspect_values = model_aspect.predict(X_test_vect)\n",
    "\n",
    "acc = metrics.accuracy_score(y_aspect_test, pred_aspect_values)\n",
    "precision = metrics.precision_score(y_aspect_test, pred_aspect_values, average='macro')\n",
    "recall = metrics.recall_score(y_aspect_test,pred_aspect_values, average='macro')\n",
    "f1 = metrics.f1_score(y_aspect_test,pred_aspect_values, average='macro')      \n",
    "    \n",
    "print(\":Aspect:\")\n",
    "print(\"Accuracy: \", acc)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"f1_score: \", f1)\n",
    "\n",
    "print('\\n')\n",
    "print('\\n')\n",
    "print('\\n')\n",
    "tn, fp, fn, tp = confusion_matrix(y_sentiment_test, pred_values).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "print(confusion_matrix(y_aspect_test,pred_aspect_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Case + N + Stop + D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CF+N+SW+D:\n",
      ":Sentiment:\n",
      "Accuracy:  0.8243727598566308\n",
      "Precision:  0.7655144801815027\n",
      "Recall:  0.8135539795114264\n",
      "f1_score:  0.7820034443168771\n",
      ":Aspect:\n",
      "Accuracy:  0.7831541218637993\n",
      "Precision:  0.7904221849966819\n",
      "Recall:  0.7814177393312983\n",
      "f1_score:  0.7832823984861899\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "107 28 70 353\n",
      "[[ 96   6   7   3  10]\n",
      " [  1  76   0  23   7]\n",
      " [  0   1  86   0  13]\n",
      " [  2  14   3  73  12]\n",
      " [  3   4   4   8 106]]\n"
     ]
    }
   ],
   "source": [
    "X_train_processed=[]\n",
    "X_test_processed=[]\n",
    "y_sentiment_train =[]\n",
    "y_aspect_train =[]\n",
    "y_sentiment_test=[]\n",
    "y_aspect_test=[]\n",
    "\n",
    "for index, row in train.iterrows():\n",
    "    processedText = case_folding(str(row['Opinion']))\n",
    "    processedText = normalisasi(processedText)\n",
    "    processedText = hapus_stopword(processedText)\n",
    "    processedText = hapus_duplikasi_kata(processedText)\n",
    "    X_train_processed.append(processedText)\n",
    "    y_sentiment_train.append(row['Sentiment'])\n",
    "    y_aspect_train.append(row['Aspect'])\n",
    "\n",
    "for index, row in test.iterrows():\n",
    "    processedText = case_folding(str(row['Opinion']))\n",
    "    processedText = normalisasi(processedText)\n",
    "    processedText = hapus_stopword(processedText)\n",
    "    processedText = hapus_duplikasi_kata(processedText)\n",
    "    X_test_processed.append(processedText)\n",
    "    y_sentiment_test.append(row['Sentiment'])\n",
    "    y_aspect_test.append(row['Aspect'])\n",
    "    \n",
    "    \n",
    "X_train_vect = count_vect.transform(X_train_processed)\n",
    "X_test_vect = count_vect.transform(X_test_processed)\n",
    "\n",
    "\n",
    "X_train_vect = X_train_vect.toarray().astype(float)\n",
    "X_train_vect = np.array(X_train_vect, dtype='float64')\n",
    "\n",
    "X_test_vect = X_test_vect.toarray().astype(float)\n",
    "X_test_vect = np.array(X_test_vect, dtype='float64')\n",
    "\n",
    "model.fit(X_train_vect,y_sentiment_train)\n",
    "pred_values = model.predict(X_test_vect)\n",
    "\n",
    "acc = metrics.accuracy_score(y_sentiment_test, pred_values)\n",
    "precision = metrics.precision_score(y_sentiment_test, pred_values, average='macro')\n",
    "recall = metrics.recall_score(y_sentiment_test,pred_values, average='macro')\n",
    "f1 = metrics.f1_score(y_sentiment_test,pred_values, average='macro')      \n",
    "    \n",
    "print(\"CF+N+SW+D:\")\n",
    "print(\":Sentiment:\")\n",
    "print(\"Accuracy: \", acc)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"f1_score: \", f1)\n",
    "\n",
    "model_aspect.fit(X_train_vect,y_aspect_train)\n",
    "pred_aspect_values = model_aspect.predict(X_test_vect)\n",
    "\n",
    "acc = metrics.accuracy_score(y_aspect_test, pred_aspect_values)\n",
    "precision = metrics.precision_score(y_aspect_test, pred_aspect_values, average='macro')\n",
    "recall = metrics.recall_score(y_aspect_test,pred_aspect_values, average='macro')\n",
    "f1 = metrics.f1_score(y_aspect_test,pred_aspect_values, average='macro')  \n",
    "    \n",
    "print(\":Aspect:\")\n",
    "print(\"Accuracy: \", acc)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"f1_score: \", f1)\n",
    "\n",
    "print('\\n')\n",
    "print('\\n')\n",
    "print('\\n')\n",
    "tn, fp, fn, tp = confusion_matrix(y_sentiment_test, pred_values).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "print(confusion_matrix(y_aspect_test,pred_aspect_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalisasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N:\n",
      ":Sentiment:\n",
      "Accuracy:  0.8154121863799283\n",
      "Precision:  0.7518261730840659\n",
      "Recall:  0.7849487785657998\n",
      "f1_score:  0.7647237016083805\n",
      ":Aspect:\n",
      "Accuracy:  0.8010752688172043\n",
      "Precision:  0.8065570448132384\n",
      "Recall:  0.8002118843619993\n",
      "f1_score:  0.800706772155048\n"
     ]
    }
   ],
   "source": [
    "X_train_processed=[]\n",
    "X_test_processed=[]\n",
    "y_sentiment_train =[]\n",
    "y_aspect_train =[]\n",
    "y_sentiment_test=[]\n",
    "y_aspect_test=[]\n",
    "\n",
    "for index, row in train.iterrows():\n",
    "    processedText = normalisasi(str(row['Opinion']))\n",
    "    X_train_processed.append(processedText)\n",
    "    y_sentiment_train.append(row['Sentiment'])\n",
    "    y_aspect_train.append(row['Aspect'])\n",
    "\n",
    "for index, row in test.iterrows():\n",
    "    processedText = normalisasi(str(row['Opinion']))\n",
    "    X_test_processed.append(processedText)\n",
    "    y_sentiment_test.append(row['Sentiment'])\n",
    "    y_aspect_test.append(row['Aspect'])\n",
    "    \n",
    "    \n",
    "X_train_vect = count_vect.transform(X_train_processed)\n",
    "X_test_vect = count_vect.transform(X_test_processed)\n",
    "\n",
    "X_train_vect = X_train_vect.toarray().astype(float)\n",
    "X_train_vect = np.array(X_train_vect, dtype='float64')\n",
    "\n",
    "X_test_vect = X_test_vect.toarray().astype(float)\n",
    "X_test_vect = np.array(X_test_vect, dtype='float64')\n",
    "\n",
    "\n",
    "model.fit(X_train_vect,y_sentiment_train)\n",
    "pred_values = model.predict(X_test_vect)\n",
    "\n",
    "acc = metrics.accuracy_score(y_sentiment_test, pred_values)\n",
    "precision = metrics.precision_score(y_sentiment_test, pred_values, average='macro')\n",
    "recall = metrics.recall_score(y_sentiment_test,pred_values, average='macro')\n",
    "f1 = metrics.f1_score(y_sentiment_test,pred_values, average='macro')  \n",
    "\n",
    "print(\"N:\")\n",
    "print(\":Sentiment:\")\n",
    "print(\"Accuracy: \", acc)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"f1_score: \", f1)\n",
    "\n",
    "model_aspect.fit(X_train_vect,y_aspect_train)\n",
    "pred_aspect_values = model_aspect.predict(X_test_vect)\n",
    "\n",
    "acc = metrics.accuracy_score(y_aspect_test, pred_aspect_values)\n",
    "precision = metrics.precision_score(y_aspect_test, pred_aspect_values, average='macro')\n",
    "recall = metrics.recall_score(y_aspect_test,pred_aspect_values, average='macro')\n",
    "f1 = metrics.f1_score(y_aspect_test,pred_aspect_values, average='macro')     \n",
    "    \n",
    "print(\":Aspect:\")\n",
    "print(\"Accuracy: \", acc)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"f1_score: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Folding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CF:\n",
      ":Sentiment:\n",
      "Accuracy:  0.8010752688172043\n",
      "Precision:  0.7324913892078071\n",
      "Recall:  0.7553191489361701\n",
      "f1_score:  0.7420056232427366\n",
      ":Aspect:\n",
      "Accuracy:  0.7939068100358423\n",
      "Precision:  0.7977552353159771\n",
      "Recall:  0.7924580382081532\n",
      "f1_score:  0.7927687753592786\n"
     ]
    }
   ],
   "source": [
    "X_train_processed=[]\n",
    "X_test_processed=[]\n",
    "y_sentiment_train =[]\n",
    "y_aspect_train =[]\n",
    "y_sentiment_test=[]\n",
    "y_aspect_test=[]\n",
    "\n",
    "for index, row in train.iterrows():\n",
    "    processedText = case_folding(str(row['Opinion']))\n",
    "    X_train_processed.append(processedText)\n",
    "    y_sentiment_train.append(row['Sentiment'])\n",
    "    y_aspect_train.append(row['Aspect'])\n",
    "\n",
    "for index, row in test.iterrows():\n",
    "    processedText = case_folding(str(row['Opinion']))\n",
    "    X_test_processed.append(processedText)\n",
    "    y_sentiment_test.append(row['Sentiment'])\n",
    "    y_aspect_test.append(row['Aspect'])\n",
    "    \n",
    "    \n",
    "X_train_vect = count_vect.transform(X_train_processed)\n",
    "X_test_vect = count_vect.transform(X_test_processed)\n",
    "\n",
    "X_train_vect = X_train_vect.toarray().astype(float)\n",
    "X_train_vect = np.array(X_train_vect, dtype='float64')\n",
    "\n",
    "X_test_vect = X_test_vect.toarray().astype(float)\n",
    "X_test_vect = np.array(X_test_vect, dtype='float64')\n",
    "\n",
    "\n",
    "model.fit(X_train_vect,y_sentiment_train)\n",
    "pred_values = model.predict(X_test_vect)\n",
    "\n",
    "acc = metrics.accuracy_score(y_sentiment_test, pred_values)\n",
    "precision = metrics.precision_score(y_sentiment_test, pred_values, average='macro')\n",
    "recall = metrics.recall_score(y_sentiment_test,pred_values, average='macro')\n",
    "f1 = metrics.f1_score(y_sentiment_test,pred_values, average='macro')    \n",
    "    \n",
    "print(\"CF:\")\n",
    "print(\":Sentiment:\")\n",
    "print(\"Accuracy: \", acc)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"f1_score: \", f1)\n",
    "\n",
    "model_aspect.fit(X_train_vect,y_aspect_train)\n",
    "pred_aspect_values = model_aspect.predict(X_test_vect)\n",
    "\n",
    "acc = metrics.accuracy_score(y_aspect_test, pred_aspect_values)\n",
    "precision = metrics.precision_score(y_aspect_test, pred_aspect_values, average='macro')\n",
    "recall = metrics.recall_score(y_aspect_test,pred_aspect_values, average='macro')\n",
    "f1 = metrics.f1_score(y_aspect_test,pred_aspect_values, average='macro')    \n",
    "    \n",
    "print(\":Aspect:\")\n",
    "print(\"Accuracy: \", acc)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"f1_score: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SW:\n",
      ":Sentiment:\n",
      "Accuracy:  0.8064516129032258\n",
      "Precision:  0.7393776704734978\n",
      "Recall:  0.7639085894405043\n",
      "f1_score:  0.7495345125681607\n",
      ":Aspect:\n",
      "Accuracy:  0.7939068100358423\n",
      "Precision:  0.7969810625778871\n",
      "Recall:  0.7910844303543859\n",
      "f1_score:  0.7928041214125927\n"
     ]
    }
   ],
   "source": [
    "X_train_processed=[]\n",
    "X_test_processed=[]\n",
    "y_sentiment_train =[]\n",
    "y_aspect_train =[]\n",
    "y_sentiment_test=[]\n",
    "y_aspect_test=[]\n",
    "\n",
    "for index, row in train.iterrows():\n",
    "    processedText = hapus_stopword(str(row['Opinion']))\n",
    "    X_train_processed.append(processedText)\n",
    "    y_sentiment_train.append(row['Sentiment'])\n",
    "    y_aspect_train.append(row['Aspect'])\n",
    "\n",
    "for index, row in test.iterrows():\n",
    "    processedText = hapus_stopword(str(row['Opinion']))\n",
    "    X_test_processed.append(processedText)\n",
    "    y_sentiment_test.append(row['Sentiment'])\n",
    "    y_aspect_test.append(row['Aspect'])\n",
    "    \n",
    "    \n",
    "X_train_vect = count_vect.transform(X_train_processed)\n",
    "X_test_vect = count_vect.transform(X_test_processed)\n",
    "\n",
    "X_train_vect = X_train_vect.toarray().astype(float)\n",
    "X_train_vect = np.array(X_train_vect, dtype='float64')\n",
    "\n",
    "X_test_vect = X_test_vect.toarray().astype(float)\n",
    "X_test_vect = np.array(X_test_vect, dtype='float64')\n",
    "\n",
    "\n",
    "model.fit(X_train_vect,y_sentiment_train)\n",
    "pred_values = model.predict(X_test_vect)\n",
    "\n",
    "acc = metrics.accuracy_score(y_sentiment_test, pred_values)\n",
    "precision = metrics.precision_score(y_sentiment_test, pred_values, average='macro')\n",
    "recall = metrics.recall_score(y_sentiment_test,pred_values, average='macro')\n",
    "f1 = metrics.f1_score(y_sentiment_test,pred_values, average='macro')   \n",
    "    \n",
    "print(\"SW:\")\n",
    "print(\":Sentiment:\")\n",
    "print(\"Accuracy: \", acc)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"f1_score: \", f1)\n",
    "\n",
    "model_aspect.fit(X_train_vect,y_aspect_train)\n",
    "pred_aspect_values = model_aspect.predict(X_test_vect)\n",
    "\n",
    "acc = metrics.accuracy_score(y_aspect_test, pred_aspect_values)\n",
    "precision = metrics.precision_score(y_aspect_test, pred_aspect_values, average='macro')\n",
    "recall = metrics.recall_score(y_aspect_test,pred_aspect_values, average='macro')\n",
    "f1 = metrics.f1_score(y_aspect_test,pred_aspect_values, average='macro')    \n",
    "    \n",
    "print(\":Aspect:\")\n",
    "print(\"Accuracy: \", acc)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"f1_score: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\n",
      ":Sentiment:\n",
      "Accuracy:  0.8154121863799283\n",
      "Precision:  0.7506329113924051\n",
      "Recall:  0.7773837667454688\n",
      "f1_score:  0.7616561402344706\n",
      ":Aspect:\n",
      "Accuracy:  0.7939068100358423\n",
      "Precision:  0.7962484815065283\n",
      "Recall:  0.7918512286242942\n",
      "f1_score:  0.7921259533525017\n"
     ]
    }
   ],
   "source": [
    "X_train_processed=[]\n",
    "X_test_processed=[]\n",
    "y_sentiment_train =[]\n",
    "y_aspect_train =[]\n",
    "y_sentiment_test=[]\n",
    "y_aspect_test=[]\n",
    "\n",
    "for index, row in train.iterrows():\n",
    "    processedText = hapus_duplikasi_kata(str(row['Opinion']))\n",
    "    X_train_processed.append(processedText)\n",
    "    y_sentiment_train.append(row['Sentiment'])\n",
    "    y_aspect_train.append(row['Aspect'])\n",
    "\n",
    "for index, row in test.iterrows():\n",
    "    processedText = hapus_duplikasi_kata(str(row['Opinion']))\n",
    "    X_test_processed.append(processedText)\n",
    "    y_sentiment_test.append(row['Sentiment'])\n",
    "    y_aspect_test.append(row['Aspect'])\n",
    "    \n",
    "    \n",
    "X_train_vect = count_vect.transform(X_train_processed)\n",
    "X_test_vect = count_vect.transform(X_test_processed)\n",
    "\n",
    "X_train_vect = X_train_vect.toarray().astype(float)\n",
    "X_train_vect = np.array(X_train_vect, dtype='float64')\n",
    "\n",
    "X_test_vect = X_test_vect.toarray().astype(float)\n",
    "X_test_vect = np.array(X_test_vect, dtype='float64')\n",
    "\n",
    "\n",
    "model.fit(X_train_vect,y_sentiment_train)\n",
    "pred_values = model.predict(X_test_vect)\n",
    "\n",
    "acc = metrics.accuracy_score(y_sentiment_test, pred_values)\n",
    "precision = metrics.precision_score(y_sentiment_test, pred_values, average='macro')\n",
    "recall = metrics.recall_score(y_sentiment_test,pred_values, average='macro')\n",
    "f1 = metrics.f1_score(y_sentiment_test,pred_values, average='macro')    \n",
    "    \n",
    "print(\"D:\")\n",
    "print(\":Sentiment:\")\n",
    "print(\"Accuracy: \", acc)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"f1_score: \", f1)\n",
    "\n",
    "model_aspect.fit(X_train_vect,y_aspect_train)\n",
    "pred_aspect_values = model_aspect.predict(X_test_vect)\n",
    "\n",
    "acc = metrics.accuracy_score(y_aspect_test, pred_aspect_values)\n",
    "precision = metrics.precision_score(y_aspect_test, pred_aspect_values, average='macro')\n",
    "recall = metrics.recall_score(y_aspect_test,pred_aspect_values, average='macro')\n",
    "f1 = metrics.f1_score(y_aspect_test,pred_aspect_values, average='macro')   \n",
    "    \n",
    "print(\":Aspect:\")\n",
    "print(\"Accuracy: \", acc)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"f1_score: \", f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
